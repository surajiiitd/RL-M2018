{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries needed \n",
    "# Reference : https://github.com/ShangtongZhang/reinforcement-learning-an-introduction/blob/master/chapter06/random_walk.py\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialisation_parameters():\n",
    "    # 0 is the left terminal state\n",
    "    # 6 is the right terminal state\n",
    "    # 1 ... 5 represents A ... E\n",
    "    VALUES = np.zeros(7)\n",
    "    VALUES[1:6] = 0.5\n",
    "    # For convenience, we assume all rewards are 0\n",
    "    # and the left terminal state has value 0, the right terminal state has value 1\n",
    "    # set up true state values\n",
    "    TRUE_VALUE = np.zeros(7)\n",
    "    TRUE_VALUE[6] = VALUES[6] = ACTION_RIGHT = 1\n",
    "    TRUE_VALUE[1:6] = np.arange(1, 6) / 6.0\n",
    "    ACTION_LEFT = 0\n",
    "    return VALUES,TRUE_VALUE,ACTION_LEFT,ACTION_RIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-47-c40cab1cc89c>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-47-c40cab1cc89c>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    if np.random.binomial(1, 0.5) = ACTION_LEFT:\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def td_loop(state,trajectory,batch,values,alpha,rewards):\n",
    "    old_state = state\n",
    "    if np.random.binomial(1, 0.5) != ACTION_LEFT:\n",
    "        state += 1\n",
    "    else:\n",
    "        state -= 1\n",
    "    # Assume all rewards are 0\n",
    "    reward = 0\n",
    "    trajectory.append(state)\n",
    "    # TD update\n",
    "    if not batch:\n",
    "        gt = (reward + values[state] - values[old_state])\n",
    "        values[old_state] += alpha * gt\n",
    "    if state == 6 or state == 0:\n",
    "        return None,None,None,None,None,None\n",
    "    ###\n",
    "    rewards.append(reward)\n",
    "    return state,trajectory,batch,values,alpha,rewards\n",
    "    \n",
    "def temporal_difference(values, alpha=0.1, batch=False):\n",
    "    '''Function for temporal difference \n",
    "    Parameters are as : \n",
    "        values: current states value, will be updated if @batch is False\n",
    "        alpha: step size\n",
    "        batch: whether to update @values'''\n",
    "    state = 3\n",
    "    trajectory = [state]\n",
    "    rewards = [0]\n",
    "    while True:\n",
    "        state,trajectory,batch,values,alpha,rewards = td_loop(state,trajectory,batch,values,alpha,rewards)\n",
    "        if state == None:\n",
    "            break\n",
    "    return trajectory, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_monte(state):\n",
    "    if np.random.binomial(1, 0.5) != ACTION_LEFT:\n",
    "        state += 1\n",
    "    else:\n",
    "        state -= 1\n",
    "    return state\n",
    "    \n",
    "def monte_carlo(values, alpha=0.1, batch=False):\n",
    "    ''' Function for Monte Carlo\n",
    "    Parameters are as:\n",
    "        values: current states value, will be updated if @batch is False\n",
    "        alpha: step size\n",
    "        batch: whether to update values\n",
    "        '''\n",
    "    state = 3\n",
    "    trajectory = [3]\n",
    "    # if end up with left terminal state, all returns are 0\n",
    "    # if end up with right terminal state, all returns are 1\n",
    "    while True:\n",
    "        state = conditional_monte(state)\n",
    "        trajectory.append(state)\n",
    "        if state == 0:\n",
    "            returns = 0.0\n",
    "            break\n",
    "        elif state == 6:\n",
    "            returns = 1\n",
    "            break\n",
    "    if not batch:\n",
    "        for state_ in trajectory[:-1]:\n",
    "            # MC update\n",
    "            gt = (returns - values[state_])\n",
    "            value_add = alpha * gt\n",
    "            values[state_] = values[state_] + value_add\n",
    "    return trajectory, [returns] * (len(trajectory) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 6.2 left\n",
    "def compute_state_loop(episodes,current_values):\n",
    "    for i in range(episodes[-1] + 1):\n",
    "        if i in episodes:\n",
    "            plt.plot(current_values, label=str(i) + ' episodes')\n",
    "        temporal_difference(current_values)\n",
    "    return current_values\n",
    "\n",
    "def compute_state_value():\n",
    "    \n",
    "    episodes = [0, 1, 10, 10*2]\n",
    "    \n",
    "    current_values = np.copy(VALUES)\n",
    "    plt.figure(1)\n",
    "    \n",
    "    current_values = compute_state_loop(episodes,current_values)\n",
    "    plt.plot(TRUE_VALUE, label='true values')\n",
    "    plt.xlabel('state')\n",
    "    plt.ylabel('estimated value')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example 6.2 right\n",
    "def rms_loop(episodes,runs,total_errors,method,alpha):\n",
    "    for r in tqdm(range(runs)):\n",
    "            errors = []\n",
    "            current_values = np.copy(VALUES)\n",
    "            for i in range(0, episodes):\n",
    "                power_true = np.power(TRUE_VALUE - current_values, 2)\n",
    "                value_new = np.sum(power_true)\n",
    "                sqrt_v = np.sqrt(value_new / 5.0)\n",
    "                errors.append(sqrt_v)\n",
    "                if method == 'TD':\n",
    "                    temporal_difference(current_values, alpha=alpha)\n",
    "                else:\n",
    "                    monte_carlo(current_values, alpha=alpha)\n",
    "            total_errors = total_errors + np.asarray(errors)\n",
    "    return total_errors\n",
    "\n",
    "def rms_cond(td_alphas):\n",
    "    if i >= len(td_alphas):\n",
    "            method = 'MC'\n",
    "            linestyle = 'dashdot'\n",
    "        else:\n",
    "            method = 'TD'\n",
    "            linestyle = 'solid'\n",
    "    return method,linestyle\n",
    "    \n",
    "def rms_error():\n",
    "    # Same alpha value can appear in both arrays\n",
    "    td_alphas = [0.15, 0.1, 0.05]\n",
    "    mc_alphas = [0.01, 0.02, 0.03, 0.04]\n",
    "    episodes = 101\n",
    "    runs = 100\n",
    "    for i, alpha in enumerate(td_alphas + mc_alphas):\n",
    "        total_errors = np.zeros(episodes)\n",
    "        method,linestyle = rms_cond(td_alphas)\n",
    "        total_errors = rms_loop(episodes,runs,total_errors,method,alpha)\n",
    "        total_errors =total_errors/runs\n",
    "        plt.plot(total_errors, linestyle=linestyle, label=method + ', alpha = %.02f' % (alpha))\n",
    "    plt.xlabel('episodes')\n",
    "    plt.ylabel('RMS')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell-pc.000\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 140.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 96.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 71.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 83.52it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 126.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 130.45it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 148.67it/s]\n"
     ]
    }
   ],
   "source": [
    "VALUES,TRUE_VALUE,ACTION_LEFT,ACTION_RIGHT = initialisation_parameters()\n",
    "plt.figure(figsize=(10, 20))\n",
    "###\n",
    "plt.subplot(2, 1, 1)\n",
    "compute_state_value()\n",
    "###\n",
    "plt.subplot(2, 1, 2)\n",
    "rms_error()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images3/example_6_2.png')\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
